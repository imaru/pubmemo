<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
    <meta name="generator" content="pandoc" />

        <meta name="author" content="Toshihide Imaruoka" />
    
    
    <title>midori5</title>

        <script src="site_libs/header-attrs-2.23/header-attrs.js"></script>
        <script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <link href="site_libs/bootstrap-3.3.7/css/bootstrap.min.css" rel="stylesheet" />
        <script src="site_libs/bootstrap-3.3.7/js/bootstrap.min.js"></script>
        <script src="site_libs/navigation-1.1/tabsets.js"></script>
        <link href="site_libs/downcute-0.1/downcute.css" rel="stylesheet" />
        <link href="site_libs/downcute-0.1/downcute_fonts_embed.css" rel="stylesheet" />
        <script src="site_libs/downcute-0.1/downcute_styles.js"></script>
        <script src="site_libs/downcute-0.1/downcute.js"></script>
        <script src="site_libs/prism-1.22/prism.js"></script>
    
    
    
        <link rel="stylesheet" href="mycss.css" type="text/css" />
    
    <!-- tabsets -->
    <script>
      $(document).ready(function () {
	  window.buildTabsets("toc");
      });
      $(document).ready(function () {
	  $('.tabset-dropdown > .nav-tabs > li').click(function () {
	      $(this).parent().toggleClass('nav-tabs-open')
	  });
      });
    </script>

    <!-- code folding -->
    
    <!-- code download -->
    
    <!-- tabsets dropdown -->

    <style type="text/css">
      .tabset-dropdown > .nav-tabs {
	  display: inline-table;
	  max-height: 500px;
	  min-height: 44px;
	  overflow-y: auto;
	  background: white;
	  border: 1px solid #ddd;
	  border-radius: 4px;
      }
      
      .tabset-dropdown > .nav-tabs > li.active:before {
	  content: "";
	  font-family: 'Glyphicons Halflings';
	  display: inline-block;
	  padding: 10px;
	  border-right: 1px solid #ddd;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
	  content: "&#xe258;";
	  border: none;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
	  content: "";
	  font-family: 'Glyphicons Halflings';
	  display: inline-block;
	  padding: 10px;
	  border-right: 1px solid #ddd;
      }
      
      .tabset-dropdown > .nav-tabs > li.active {
	  display: block;
      }

      .tabset-dropdown > .nav-tabs > li.active a {
  	  padding: 0 15px !important;
      }

      .tabset-dropdown > .nav-tabs > li > a,
      .tabset-dropdown > .nav-tabs > li > a:focus,
      .tabset-dropdown > .nav-tabs > li > a:hover {
	  border: none;
	  display: inline-block;
	  border-radius: 4px;
	  background-color: transparent;
      }
      
      .tabset-dropdown > .nav-tabs.nav-tabs-open > li {
	  display: block;
	  float: none;
      }
      
      .tabset-dropdown > .nav-tabs > li {
	  display: none;
	  margin-left: 0 !important;
      }
    </style>
    
</head>

<body class="preload">

   	
               <!-- downcute start -->   
   <div id="docute" class="Root theme-default">
     <div class="Page layout-narrow">
      <div class="Wrap">
        <div class="Sidebar">
          <div class="SidebarItems" id="toc">
            <ul>
            <li><a href="#glmの尤度比検定と検定の非対称性"
            id="toc-glmの尤度比検定と検定の非対称性">5.
            GLMの尤度比検定と検定の非対称性</a>
            <ul>
            <li><a href="#統計学的な検定のわくぐみ"
            id="toc-統計学的な検定のわくぐみ">5.1
            統計学的な検定のわくぐみ</a></li>
            <li><a href="#尤度比検定の例題逸脱度の差を調べる"
            id="toc-尤度比検定の例題逸脱度の差を調べる">5.2
            尤度比検定の例題：逸脱度の差を調べる</a></li>
            <li><a href="#種類の過誤と統計学的な検定の非対称性"
            id="toc-種類の過誤と統計学的な検定の非対称性">5.3
            2種類の過誤と統計学的な検定の非対称性</a></li>
            <li><a href="#帰無仮説を棄却するための有意水準"
            id="toc-帰無仮説を棄却するための有意水準">5.4
            帰無仮説を棄却するための有意水準</a></li>
            <li><a href="#方法2-chi2分布を使った近似計算法"
            id="toc-方法2-chi2分布を使った近似計算法">5.4.2 方法(2)
            <span
            class="math inline">\(\chi^2\)</span>分布を使った近似計算法</a></li>
            <li><a href="#帰無仮説を棄却できないは差がないではない"
            id="toc-帰無仮説を棄却できないは差がないではない">5.5
            「帰無仮説を棄却できない」は「差がない」ではない</a></li>
            <li><a
            href="#検定とモデル選択そして推定された統計モデルの解釈"
            id="toc-検定とモデル選択そして推定された統計モデルの解釈">5.6
            検定とモデル選択、そして推定された統計モデルの解釈</a></li>
            <li><a href="#この章のまとめの参考文献"
            id="toc-この章のまとめの参考文献">5.7
            この章のまとめの参考文献</a></li>
            </ul></li>
            </ul>
          </div>
          <div data-position="sidebar:post-end" class="InjectedComponents"><div class="dark-theme-toggler"><div class="toggle "><div class="toggle-track"><div class="toggle-track-check"><img  src="data:image/png;base64,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" role="presentation" style="pointer-events: none;" width="16" height="16"></div> <div class="toggle-track-x"><img src="data:image/png;base64,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" role="presentation" style="pointer-events: none;" width="16" height="16"></div></div> <div class="toggle-thumb"></div></div> <input type="checkbox" aria-label="Switch between Dark and Default theme" class="toggler-screen-reader-only"></div></div>
        </div>
        <div class="Main">
          <div class="Content" id="content"> 
   
   
      
      <div class="navbar navbar-default  navbar-fixed-top" role="navigation">
        <div class="container">
          <div class="navbar-header">
            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
              <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="index.html">my public memo</a>
          </div>
          <div id="navbar" class="navbar-collapse collapse">
            <ul class="nav navbar-nav">
              <li>
        <a href="index.html">Home</a>
      </li>
      <li>
        <a href="midori1.html">緑本</a>
      </li>
      <li>
        <a href="baba1.html">馬場本1部</a>
      </li>
      <li>
        <a href="baba2.html">馬場本2部</a>
      </li>
      <li>
        <a href="baba3.html">馬場本3部</a>
      </li>
      <li>
        <a href="baba4.html">馬場本4部</a>
      </li>
      <li>
        <a href="psytech.html">技術部</a>
      </li>
            </ul>
            <ul class="nav navbar-nav navbar-right">
              
            </ul>
          </div><!--/.nav-collapse -->
        </div><!--/.container -->
      </div><!--/.navbar -->
        
      <h1 class="title">midori5</h1>
      
      <p class="authors">
           <span class="glyphicon glyphicon-user"></span> Toshihide
Imaruoka
      </p>
         <p class="date"><span class="glyphicon glyphicon-calendar"></span> 6/16/2022</p>
           

   
      
   
<!-- Don't indent these lines or it will mess pre blocks indentation --> 
<div class="page-content has-page-title">
<div id="glmの尤度比検定と検定の非対称性" class="section level1">
<h1>5. GLMの尤度比検定と検定の非対称性</h1>
<ul>
<li>検定についての章</li>
<li>尤度比検定：ネストしてるモデル同士の比較</li>
<li>パラメトリック検定を「正規分布を使った」とするのは誤用</li>
</ul>
<div id="統計学的な検定のわくぐみ" class="section level2">
<h2>5.1 統計学的な検定のわくぐみ</h2>
<ul>
<li>図5.1
<ul>
<li>統計モデルの検定とAICによるモデル選択の比較</li>
<li>統計モデル検定の帰無仮説・対立仮説の考え方次第では、結構似てる
<ul>
<li>あるモデルを帰無仮説、別のモデルを対立仮説と考える</li>
<li>ただし、パラメータを推定した後の手続きは異なる
<ul>
<li>帰無仮説の特別扱い</li>
</ul></li>
<li>Neyman-Peason（ネイマン・ピアソン）
<ul>
<li>帰無仮説を真のモデルを考え、</li>
<li>真のモデルから得られる検定統計量を調べて「ありがちな範囲」を設定</li>
<li>対立仮説モデルから得られる検定統計量が上の範囲内かどうかを確認</li>
</ul></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="尤度比検定の例題逸脱度の差を調べる" class="section level2">
<h2>5.2 尤度比検定の例題：逸脱度の差を調べる</h2>
<ul>
<li>第3章の種子数データを使う</li>
<li>統計モデル：<span
class="math inline">\(\lambda_i=exp(\beta_1+\beta_2x_i)\)</span>を平均とするポアソン分布GLM
<ul>
<li>一定モデル：<span class="math inline">\(y_i\sim
\beta_1\)</span></li>
<li>xモデル：<span class="math inline">\(y_i\sim
\beta_1+\beta_2x_i\)</span></li>
<li>一定モデルが帰無仮説</li>
</ul></li>
<li>逸脱度は算出済み
<ul>
<li>一定モデル：<span class="math inline">\(D=475.3\)</span></li>
<li>xモデル：<span class="math inline">\(D=470.8\)</span></li>
<li>差は4.5くらい</li>
</ul></li>
<li>尤度比
<ul>
<li><span
class="math inline">\(\frac{L_1^*}{L_2^*}=\frac{一定モデルの最大尤度}{xモデルの最大尤度}=\frac{対数尤度のexpだからexp(-237.6)}{exp(-235.4)}\)</span></li>
<li>ただし、このままは使わず、尤度比の対数をとって-2をかける
<ul>
<li><span
class="math inline">\(log(\frac{L_1^*}{L_2^*})=log(L_1^*)-log(L_2^*)\)</span>に-2をかける</li>
<li>上の式は逸脱度Dの差に等しい</li>
<li>つまり、尤度比は逸脱度Dの差のこと</li>
<li>逸脱度の差（尤度比）を<span
class="math inline">\(\Delta{D}_{1,2}\)</span>と表す</li>
</ul></li>
<li>尤度比4.5が（逸脱度が）改善されたと言っていいのかどうかという問題を考える</li>
</ul></li>
</ul>
</div>
<div id="種類の過誤と統計学的な検定の非対称性" class="section level2">
<h2>5.3 2種類の過誤と統計学的な検定の非対称性</h2>
<ul>
<li>Neyman-Pearsonで考えるので、モデルを帰無仮説と対立仮説として考える
<ul>
<li>帰無仮説：一定モデル</li>
<li>対立仮説：xモデル</li>
</ul></li>
<li>このとき、「帰無仮説が正しくなければ対立仮説は正しい」は真だけど、対偶の「対立仮説が正しくなければ帰無仮説は正しい」は真ではない→5.5で詳しく</li>
<li>表5.2に第一種の過誤と第二種の過誤の話</li>
<li>どちらの過誤も防ぐのは大変</li>
<li>Neyman-Pearson：第一種の過誤を避けることに専念しよう
<ol style="list-style-type: decimal">
<li>帰無仮説（一定モデル）を正しいものだと仮定</li>
<li>観測データに一定モデルをあてはめ、最大対数尤度となるパラメータを決定（＝2.06）。これを真のモデルと同じとする。</li>
<li>真のモデル（<span
class="math inline">\(\hat{\beta_1}=2.06\)</span>からデータを繰り返し生成。データに対して一定モデルとxモデルを当てはめ、<span
class="math inline">\(\Delta{D_{1,2}}\)</span>を得て、その分布をみる</li>
<li>分布から<span class="math inline">\(\Delta
D_{1,2}\geqq4.5\)</span>となる確率<span
class="math inline">\(P\)</span>がわかるので評価できる</li>
</ol></li>
<li>第一種過誤の重視＝検定の非対称性</li>
</ul>
</div>
<div id="帰無仮説を棄却するための有意水準" class="section level2">
<h2>5.4 帰無仮説を棄却するための有意水準</h2>
<ul>
<li><span class="math inline">\(P\)</span>値：<span
class="math inline">\(\Delta D_{1,2}\geqq4.5\)</span>となる確率
<ul>
<li>第一種の過誤をおかす確率</li>
<li><span
class="math inline">\(P\)</span>値が大きい＝そのくらいの差はよくあること＝帰無仮説を棄却できない</li>
<li><span
class="math inline">\(P\)</span>値が小さい＝その差は滅多にない＝帰無仮説を棄却する（真のモデルとは思えないから）</li>
</ul></li>
<li>大きい/小さいの基準は？</li>
<li>有意水準<span
class="math inline">\(\alpha\)</span>を事前に決めておく
<ul>
<li><span
class="math inline">\(P\geqq\alpha\)</span>：帰無仮説は棄却できない</li>
<li><span
class="math inline">\(P&lt;\alpha\)</span>：帰無仮説を棄却できる</li>
</ul></li>
<li><span class="math inline">\(\alpha\)</span>はどう決める？
<ul>
<li>まあ何となく</li>
<li>伝統的に</li>
</ul></li>
</ul>
<div id="方法1-汎用性のあるパラメトリックブートストラップ法"
class="section level3">
<h3>5.4.1 方法(1) 汎用性のあるパラメトリックブートストラップ法</h3>
<ul>
<li><span
class="math inline">\(P\)</span>値を評価するための分布があれば良いことになる</li>
<li>まず1つめ：パラメトリックブートストラップ法（BP法）
<ul>
<li>乱数発生によるシミュレーションでデータたくさん生成</li>
<li>以下、Rでの手順
<ol style="list-style-type: decimal">
<li>一定モデルとxモデルの最尤推定を実施し、結果をfit1とfit2に取得</li>
<li>2つのモデルの残差逸脱度（変数deviance)が分かるので、その差から<span
class="math inline">\(\Delta D_{1,2}\)</span>を算出。これが尤度比。</li>
<li>一定モデルから推定された平均種子数（推定された<span
class="math inline">\(\beta_1\)</span>をexpに）、それをラムダとしてrpois()でデータを100個生成</li>
</ol>
<ul>
<li>ここで本ではrpois()に渡す値をmean(d$y)と計算してるんだけど、ちょっとしっくりこない。</li>
</ul>
<ol start="4" style="list-style-type: decimal">
<li>生成した100個の値に対して、一定モデルとxモデルを適用し、その結果から尤度比を算出</li>
<li>以上を1000回くらい繰り返す</li>
</ol></li>
<li>実装してみよう
<ul>
<li>下の結果から、「逸脱度の差(4.51)のP値は0.035であり、有意水準0.05よりも小さいので帰無仮説を棄却し、xモデルを採択」と言える</li>
</ul></li>
</ul></li>
</ul>
<pre class="r"><code>dat&lt;-read.csv(&#39;kubobook_2012-2/poisson/data3a.csv&#39;)
dat$f&lt;-as.factor(dat$f)
f1&lt;-glm(y~1, data=dat, family=poisson)
f2&lt;-glm(y~1+x, data=dat, family=poisson)
d1&lt;-f1$deviance-f2$deviance

#nrp=10000
#for (rp in 1:nrp){
#  dat$rnd&lt;-rpois(100, lambda=mean(dat$y))
#  fit1&lt;-glm(rnd~1, data=dat, family=poisson)
#  fit2&lt;-glm(rnd~x, data=dat, family=poisson)
#  d[rp]&lt;-fit1$deviance-fit2$deviance
#}

# 上のは遅くてきついので、本を参考に関数を作成

# datを引数として逸脱度の差を返す関数
get.D&lt;-function(dat){
  nsample&lt;-nrow(dat)
  ymean&lt;-mean(dat$y)
  dat$rnd&lt;-rpois(nsample, lambda=mean(dat$y))
  fit1&lt;-glm(rnd~1, data=dat, family=poisson)
  fit2&lt;-glm(rnd~x, data=dat, family=poisson)
  fit1$deviance-fit2$deviance # ここが戻り値になる？
}

# datと繰り返し回数を引数として、get.Dを繰り返す関数
pb&lt;-function(dat, n.bs){
  replicate(n.bs, get.D(dat))
}

nr=10000
D12&lt;-pb(dat, n.bs=nr)


summary(D12)</code></pre>
<pre><code>##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
##  0.00000  0.09789  0.46726  1.00734  1.32467 17.71927</code></pre>
<pre class="r"><code>hist(D12)
abline(v=d1, lty=2)</code></pre>
<p><img src="midori5_files/figure-html/unnamed-chunk-1-1.png" width="768" /></p>
<pre class="r"><code>sum(D12&gt;d1)/nr</code></pre>
<pre><code>## [1] 0.0351</code></pre>
</div>
</div>
<div id="方法2-chi2分布を使った近似計算法" class="section level2">
<h2>5.4.2 方法(2) <span
class="math inline">\(\chi^2\)</span>分布を使った近似計算法</h2>
<ul>
<li>PB法はどんなときにも使えるけど、シミュレーションが必要</li>
<li>近似計算でもっと楽にやれる場合もある</li>
<li>Rを使った実施例
<ul>
<li>逸脱度の差が自由度1の<span
class="math inline">\(\chi^2\)</span>分布に近似（する場合がある）</li>
<li>anova関数の引数にfit1(glmの一定モデル結果)とfit2(xモデル結果)を渡して逸脱度の分析
<ul>
<li>anova()
<ul>
<li>1つあるいは複数のfitted model
objectの分散（あるいは逸脱度）分析を計算</li>
<li>lmやglmの結果を引数とする</li>
</ul></li>
</ul></li>
<li>有意確率が得られる。ただしPB法の確率と一致しない。サンプル数が小さい場合、<span
class="math inline">\(\chi^2\)</span>には近似しにくい</li>
</ul></li>
<li>サンプル数が小さいときはPB法を使うべき</li>
<li>データの分布が等分散正規分布なら、t検定や分散比を統計量としたF検定（分散分析）も使えるよ。</li>
</ul>
<pre class="r"><code>fit1&lt;-glm(y~1, data=dat, family=poisson)
fit2&lt;-glm(y~x, data=dat, family=poisson)
anova(fit1, fit2, test=&#39;Chisq&#39;)</code></pre>
<pre><code>## Analysis of Deviance Table
## 
## Model 1: y ~ 1
## Model 2: y ~ x
##   Resid. Df Resid. Dev Df Deviance Pr(&gt;Chi)  
## 1        99     89.507                       
## 2        98     84.993  1   4.5139  0.03362 *
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</code></pre>
</div>
<div id="帰無仮説を棄却できないは差がないではない"
class="section level2">
<h2>5.5 「帰無仮説を棄却できない」は「差がない」ではない</h2>
<ul>
<li><span
class="math inline">\(P&lt;\alpha\)</span>の場合、帰無仮説を棄却する</li>
<li>じゃあ<span class="math inline">\(P\geqq\alpha\)</span>の場合は？
<ul>
<li>「帰無仮説は正しい」ではない
<ul>
<li>対偶はなりたたない</li>
</ul></li>
<li>どちらも採択しない。判断を保留するのが正しい。</li>
</ul></li>
<li>Neyman-Pearsonのわくぐみの非対称性（5.3節）
<ul>
<li>第一種の過誤を棄却することを頑張ってる分、逆は弱い</li>
</ul></li>
<li>第二種の過誤の確率を<span
class="math inline">\(P_2\)</span>として評価することも可能
<ul>
<li>ただし、<span
class="math inline">\(P_2\)</span>を使って何か、というやり方が決まっているわけではない</li>
<li>検定力(<span
class="math inline">\(1-P_2\)</span>)＝帰無仮説が誤りだったときに、それを正しく棄却する確率として使うことが多い</li>
<li>実験研究では事前に検定力を定量的に決めることが望まれる
<ul>
<li>A prioriとかPost hocとか</li>
<li>G*Power使ったりとか</li>
<li><a
href="https://www.mizumot.com/method/mizumoto-takeuchi.pdf">水本・竹内,
2010</a></li>
</ul></li>
</ul></li>
</ul>
</div>
<div id="検定とモデル選択そして推定された統計モデルの解釈"
class="section level2">
<h2>5.6 検定とモデル選択、そして推定された統計モデルの解釈</h2>
<ul>
<li>尤度比検定とモデル選択：どちらも逸脱度（<span
class="math inline">\(logL^*\times -2\)</span>）</li>
<li>モデル選択
<ul>
<li>目的は「良い予測をするモデル」</li>
<li>予測の良さ＝平均対数尤度</li>
<li><span class="math inline">\(平均対数尤度＝-2\times
最大対数尤度-パラメータ数\)</span></li>
</ul></li>
<li>尤度比検定
<ul>
<li>目的は帰無仮説を安全（間違えないように）に棄却すること
<ul>
<li>棄却後に残った仮説＝対立仮説の評価は実はしない</li>
</ul></li>
</ul></li>
<li>いずれの場合も、モデルが選択されるかどうか、有意となるかどうかと効果の大きさには関係がない</li>
</ul>
</div>
<div id="この章のまとめの参考文献" class="section level2">
<h2>5.7 この章のまとめの参考文献</h2>
<ul>
<li>Neuman-Pearsonではパラメータの少ないモデルを帰無仮説とする。帰無仮説の棄却に専念＝検定の非対称性</li>
<li>尤度比検定の統計量は逸脱度の差</li>
<li>Neuman-Pearsonでは帰無仮説が棄却できなかったときは何も言えない</li>
</ul>
</div>
</div>
</div>

   
   
              </div>
  </div>
  </div>
  </div>
   
      

  <script>
    $(document).ready(function () {

		// add bootstrap table styles to pandoc tables
	$('tr.header').parent('thead').parent('table').addClass('table table-condensed');
		
 		
	    });
  </script>



    <!-- dynamically load mathjax for compatibility with self-contained -->
  <script>
    (function () {
	var script = document.createElement("script");
	script.type = "text/javascript";
	script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
	document.getElementsByTagName("head")[0].appendChild(script);
    })();
  </script>
  
</body>
</html>
